{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соединеним файлы в  единый датасет. Для понимания на каком языке написан датасет, используем библиотеку langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'data/'\n",
    "\n",
    "langs = []\n",
    "langCount = {}\n",
    "train_table = {'article': [], 'abstract': []}\n",
    "ind = {}\n",
    "for j in range(5):\n",
    "    table = pd.read_parquet(path + f'train-0000{j}-of-00005.parquet')\n",
    "    for i in table.values:\n",
    "        if i[0] != '':\n",
    "            train_table['article'].append(i[0])\n",
    "            train_table['abstract'].append(i[1])\n",
    "\n",
    "            lang = detect(i[1])\n",
    "            if lang not in langs:\n",
    "                langs.append(lang)\n",
    "                langCount[lang]=1\n",
    "                ind[lang] = i[1]\n",
    "            else:\n",
    "                langCount[lang]+=1\n",
    "    print('iter:', j+1)\n",
    "\n",
    "\n",
    "train = pd.DataFrame(train_table)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно узнать на каких языках написаны статьи, а также сколько статей написаны на определённом языке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['en', 'fr', 'it'], {'en': 117106, 'fr': 1, 'it': 1})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs, langCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почти все статьи написаны на английском. Выкинем лишние, чтобы улучшить качество обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117106, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in langs:\n",
    "    if i == 'en': continue\n",
    "    train = train[train['abstract']!= ind[i]]\n",
    "    \n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверка на наличие заглавных букв\n",
    "train['article'].apply(lambda x: x.istitle()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе анализа данных мы поняли, что в датасете находятся статьи, связанные с медицинскими иследованиями, биологией, химией.\n",
    "Главная особенность научных статей -  большое количество цифр, сокращений, вставных конструкций. Так, например в строке 65581 есть проценты, нумерование пунктов. В нулевой строке же в виде вставных конструкций фигурирует вероятность, которая обозначается буквой p. То есть модель должна научиться понимать сокращения и формулы. Проблемой так же может быть возникновение узконаправленных и редких терминов. В датасете так же было большое количество строк, на вход которых подавалась пустая строка, а на выходе был сокращенный текст. Данную проблему мы решили на момент загрузки датасета\n",
    "\n",
    "В датасете в столбцах article и abstract нет заглавных букв, а так же все знаки препинания отделены пробелами, то есть датасет уже токенизирован. Это значит, что нам не нужно обрабатывать данные. При внедрении модели в продукт надо будет подавать ей токенизированный текст.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#### Выбор метрики\n",
    "1. Метрика ROUGE\n",
    "Метрика ROUGE состоит из recall, precision и f1-score для задач суммаризации, которые задаются следующим образом:\n",
    "\n",
    "$$ recall = \\frac{Количество\\;слов,\\;совпавших\\;с\\;abstract}{количество\\;слов\\;в\\;abstract}$$\n",
    "\n",
    "$$ precision = \\frac{Количество\\;слов\\;совпавших\\;с\\;abstract}{количество\\;сгенерированных\\;слов}$$\n",
    "\n",
    "$$ F1_{score} = 2*\\frac{precision*recall}{precision+recall}$$\n",
    "\n",
    "Плюсы данной метрики в легкой интерпретируемости и понятности.\n",
    "\n",
    "2. Метрика сходства\n",
    "\n",
    "Метрика сходства считает косинус угла между сгенерированным и эталонным (abstract) текстом, представляя данные предложения как вектора. Пусть A - вектор abstract, B - вектор сгенерированного текста\n",
    "\n",
    "$$Similarity(A,B) = cos\\theta = \\frac{A*B}{|A|*|B|}$$\n",
    "\n",
    "Данная метрика может показывать эффективность модели, однако интерпретировать её и понимать где недочеты (в отличие от тех же recall и precision в ROGUE) нельзя.\n",
    "\n",
    "3. Метрика BLEU\n",
    "Метрика BLEU состоит из precision и штрафа за краткость. Precision в случае BLEU рассчитывается следующим образом:\n",
    "\n",
    "$$precision = \\frac{Количество\\;слов\\;и\\;словосочетаний,\\;совпаших\\;с\\;abstract}{Количество\\;слов\\;и\\;словосочетаний,\\;совпаших\\;в\\;abstract}$$\n",
    "\n",
    "Под словосочетанием в данном случае подразумевается пара рядом стоящих слов. Обозначим длину сгенерированного текста за c,а эталонного за r. Штраф  высчитывается следующим образом:\n",
    "$$\n",
    "BP = \n",
    "    \\begin{cases}\n",
    "    1, \\;\\;если \\;c>r \\\\\n",
    "    e^{(1-r/c)}, \\;\\;если \\;c\\leq r\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "$$BLEU = BP * precision$$\n",
    "\n",
    "Данная метрика, в отличие от остальных, подсчитывает ещё и словосочетания.\n",
    "\n",
    "\n",
    "В ходе совместных раздумий мы решили использовать метрику ROUGE, а также при необходимости его модернизации, считающие словосочетания, так как мы считаем, что ROUGE самая понятная и легкоинтерпретируемая метрика. Precision и recall довольно точно могут показать недостатки модели,  которые могут появиться при обучении. Для подсчета метрики мы будем использовать библиотеку evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
